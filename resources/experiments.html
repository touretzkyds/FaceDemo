<!DOCTYPE html>
<html>

<head>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/css/materialize.css">
    <link rel="stylesheet" href="styles.css">
    <meta charset="utf-8">
</head>

<body class="center-content" style="margin-right: 50px; margin-left: 50px; max-width: 992px;">

<table width=800><tr><td>

<h2 style="text-align: center;">TinyYoloV2 Face Detection: Experiments</h2>

<center>
  Navigation: <a href="../index.html">Return to Demo</a> or <a href="tutorial.html">View Tutorial</a><p/>
</center><p/>

See
the <a href="https://ai4k12.org/wp-content/uploads/FaceDemo-Part-1.pdf">FaceDemo
Activity Resource Guide Part 1</a> for more comprehensive treatment of
these experiments.</a>

<h5 style="text-align: left;">Layer 1 Feature Detectors</h5>

The layer 1 (conv1) kernels are 3x3 feature detectors sensitive to
color, oriented edges, or some combination of the two.  You can
measure the responses of feature detectors by holding up various
stimuli to the camera.<p/>

<b>Color detection:</b>

<ul class="fixed">
  <li> <b>Expt. 1:</b> Use a color palette such as the rainbow figure
below to measure each kernel's reponse to color.  <p/>

<center>
  <img src="rainbow-labeled.png" width=500><br clear=all>
  Color code: (R)ed, (O)range, (Y)ellow, (G)reen, (B)lue, (I)ndigo, (V)iolet. <p/>
</center>

  <li> <b>Expt. 2:</b> Notice that kernel 11, labeled the "Red patch
detector", also responds to violet, because violet is a mixture of
blue and red.  How accurate are the other kernel color descriptions?
Test them and see.  <p/>

  <li> <b>Expt. 3:</b> Which kernel responds best to light-colored
skin?  Which responds best to dark-colored skin?  Which responds well
to lips?  Which responds well to eyes?<p/>

</ul>

<b>Orientation detection:</b> Some kernels look for horizontal,
vertical, or diagonal edges.  For example, kernel 8 is a diagonal edge
detector that looks for a row of light pixels above a row of dark
pixels.  It doesn't care about color, so the R, G, and B channels of
kernel 8, each of which has a 3x3 pattern of weights, are similar: the
top left corner has positive weights and the bottom right corner has
negative weights.<p/>

<center>
<img src="squares.png" width=500><br clear=all><p/>
</center>

<ul class="fixed">
  <li> <b>Expt. 4:</b> Hold up a black square to the camera and
    observe that kernel 8 responds most strongly to the top edge of
    the square, and a bit less strongly to the left edge.  If you
    rotate the square by 30 degrees in one direction, the kernel
    responds strongly to both the top diagonal edges, and not to the
    bottom diagonal edges.  But if you rotate it by 30 degrees in the
    other direction, the kernel responds to only one of the four
    diagonal diagonal edges.  Why?<p/>

  <li> <b>Expt. 5:</b> Kernel 4 is a little messier but is also
    basically a diagonal edge detector.  Compare its weight pattern to
    that of kernel 8.  Based on the differences in the weights, how
    would you expect kernel 4 to respond to the black square stimulus?
    Show it the square and test your prediction.<p/>

  <li> <b>Expt. 6:</b> Try showing the checkerboard patterns below to
    kernels 4 and 8.  Since each kernel looks at only a 3x3 patch of
    pixels, it doesn't know that it's looking at a checkerboard.  But
    do the checkerboards make it easier for you to see how the kernels
    respond to changes in orientation?<p/>

<center>
<img src="checkerboard.png" width=700><br clear=all><p/>
</center>

  <li> <b>Expt. 7:</b> Explore the other kernels' edge responses.
    Which kernels are sensitive to the orientations of the edges?
    Which kernels are not?  How do their weights differ?<p/>

</ul>

<h5 style="text-align: left;">Layer 4 Feature Detectors</h5>

Max pooling layer 4 is a hidden layer that has seven convolutional
layers and three previous max pooling layers leading up to it, so its
units are affected by larger patches of the image: 46x46 pixels
vs. 3x3 pixels for convolutional layer 1.  These kernels compute more
complex features than just edges or color patches.  There are 128
kernels in this layer, so there are 128 different features being
represented.  It's hard to say exactly what these features are.  But
each kernel at this layer, when convolved with the preceding layer's
output, generates a 14x14 image, so we can investigate the kernels by
supplying various input images and seeing how they respond.<p/>

The demo starts out by displaying kernels 26, 36, 46, and 112.  These
appear to be eye detectors.

<ul class="fixed">
  <li> <b>Expt 8:</b> How do these kernels respond to photographs of a
  single eye?<p/>

    <center>
      <img src="eye-photos.png" width=700><br clear=all><p/>
    </center>

  <li> <b>Expt 9:</b> How do these kernels respond to drawings of a single eye?<p/>

    <center>
      <table><tr>
	  <td><img src="eye-drawing1.png" width=300></td>
	  <td width=200></td>
	  <td><img src="eye-drawing2.png" width=300></td>
	</tr>
      </table><br clear=all><p/>
    </center>


  <li> <b>Expt 10:</b> How do these kernels respond to circles?<p/>

    <center>
      <img src="circle-images.png" width=700><br clear=all><p/>
    </center>

  <li> <b>Expt 11:</b> How do these kernels respond to abstract eye shapes?<p/>

    <center>
      <img src="oval-images.png" width=700><br clear=all><p/>
    </center>

  <li> <b>Expt 12:</b> What other facial feature detectors can you
    find?  Candidates to consider: mouth detectors, nose detectors,
    chin detectors, hairline detectors.

</ul>

<h5 style="text-align: left;">Output Layer: Face Detection</h5>

<ul class="fixed">
  <li>Human photographs</li>
  <li>Line drawings of faces</li>
  <li>Missing features (eyes, mouth)</li>
  <li>Animal faces</li>
  <li>Cartoon characters</li>
  <li>Sideways or upside-down faces</li>
  <li>Why do the bounding box candidates change colors?</li>
</ul>

<p>
</p>

<h5>Download <a href="test-patterns.pdf" download="test-patterns">Test Patterns</a></h5>

</td></tr></table>

</body>
</html>
